{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please give the 3 letter State code:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------\n",
    "# input block\n",
    "# -----------\n",
    "\n",
    "# -----------------------------------\n",
    "# set one of the following to be True\n",
    "# -----------------------------------\n",
    "i_train_input       = 0 \n",
    "i_test_input        = 0\n",
    "i_application_input = 1\n",
    "\n",
    "# ------------------------------------\n",
    "# Select States(with 2 audits) to test\n",
    "# ------------------------------------\n",
    "states_test=['IRN','DNK','BGR','UZB','SEN','BWA'] # States to be removed in the training list\n",
    "\n",
    "# ---------------------------\n",
    "if i_application_input:\n",
    "    print('Please give the 3 letter State code:\\n')\n",
    "states_to_predict=['PRK','TLS','COM','ZWE','TUN','TKM','OMN','SAU','BOL','COL','CIV','SEN']\n",
    "year_to_predict= 2019\n",
    "\n",
    "# ----------------\n",
    "# defaut parameter\n",
    "# ----------------\n",
    "row = ['EI','dYear','GDP','ce6','ce3','ce2'] # accident, ICVM\n",
    "nb_inputs = len(row)\n",
    "nb_outputs = 3  # decrease (more than 10%) [0 0 1], stable [0 1 0], increase (more than 10%) [1 0 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 States have at least 2 EI data:\n",
      " ['KGZ', 'BHS', 'NZL', 'ARM', 'TZA', 'MRT', 'MYS', 'EGY', 'GMB', 'IND', 'BGR', 'DEU', 'SEN', 'UZB', 'UKR', 'PHL', 'ISR', 'HND', 'MAR', 'ETH', 'PAN', 'NOR', 'PER', 'POL', 'THA', 'TJK', 'AUS', 'IRN', 'GTM', 'COL', 'DNK', 'KEN', 'MMR', 'LKA', 'BOL', 'BRA', 'KHM', 'LBN', 'AZE', 'SYC', 'ZAF', 'GRC', 'KWT', 'NGA', 'JOR', 'GEO', 'IDN', 'BWA', 'RUS', 'QAT']  among 187\n",
      "\n",
      "Validation States: ['PRK', 'TLS', 'COM', 'ZWE', 'TUN', 'TKM', 'OMN', 'SAU', 'BOL', 'COL', 'CIV', 'SEN']\n",
      "[2017, 2007]\n",
      "[2019, 2016, 2006]\n",
      "[[2019. 2019. 2019. 2019. 2019. 2019. 2019. 2019. 2019. 2019. 2019. 2019.]\n",
      " [2008. 2010. 2008. 2010. 2009. 2010. 2010. 2009. 2008. 2017. 2008. 2016.]]\n",
      "middle year [2013. 2014. 2013. 2014. 2014. 2014. 2014. 2014. 2013. 2018. 2013. 2017.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11.,  9., 11.,  9., 10.,  9.,  9., 10., 11.,  2., 11.,  3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------\n",
    "# first create list of States with two Audits and Year of each Audit\n",
    "#--------------------------------------------------------------------\n",
    "url='https://v4p4sz5ijk.execute-api.us-east-1.amazonaws.com/anbdata/states/usoap/activity-list?api_key=00cfdca0-7039-11e9-9730-617277d0f137&format=json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read().decode(\"utf-8\"))\n",
    "df=pd.DataFrame(data) #print(df.columns)\n",
    "\n",
    "df_grp_act_St    = df.groupby(['Activity','isFinal'])['State'].apply(list)\n",
    "df_grp_act_Y     = df.groupby(['Activity','State','isFinal'])['Year'].apply(list)\n",
    "df_grp_act_EI    = df.groupby(['Activity','State',])['overall'].apply(list)\n",
    "\n",
    "#---------------\n",
    "act1='CMA Audit'\n",
    "status=1 # True: final report\n",
    "#---------------\n",
    "states_all =[] # list of all States\n",
    "states_2 =[] # list of States with at least two CMA Audit\n",
    "\n",
    "for etat in df_grp_act_St[act1,status]:\n",
    "    states_all.append(etat)\n",
    "    if len(df_grp_act_Y[act1,etat,status])>=2:\n",
    "        states_2.append(etat)\n",
    "        \n",
    "states_2.remove('SMR')\n",
    "states_2.remove('SMR') # no economy data after 2008\n",
    "A=set(states_2)\n",
    "states_ls_2 = list(A)\n",
    "B=set(states_all)\n",
    "states_ls_all = list(B)\n",
    "print(len(states_ls_2),'States have at least 2 EI data:\\n',states_ls_2, ' among', len(states_ls_all))\n",
    "\n",
    "if i_train_input:\n",
    "    print('\\ncreating inputs for the training.......')\n",
    "    for St in states_test:\n",
    "        states_ls_2.remove(St)\n",
    "        \n",
    "if i_test_input:\n",
    "    print('\\ncreating inputs for the validation test.......')\n",
    "    print('\\nValidation States:', states_test)\n",
    "    states_ls_2 = states_test\n",
    "if i_application_input:\n",
    "    states_ls_2 =states_to_predict\n",
    "    print('\\nValidation States:', states_to_predict)\n",
    "year_ls_2=np.zeros((len(states_ls_2),2))\n",
    "mid_year_ls_2=np.zeros(len(states_ls_2))\n",
    "dYear=np.zeros(len(states_ls_2))\n",
    "\n",
    "#-----------------------------------------------\n",
    "istate =0\n",
    "for etat in states_ls_2:\n",
    "    year_ls_2[istate,0]  = int(df_grp_act_Y[act1][etat][status][0])\n",
    "    year_ls_2[istate,1]  = int(df_grp_act_Y[act1][etat][status][-1])\n",
    "    if etat=='SEN' or etat=='COL':\n",
    "        print(df_grp_act_Y[act1][etat][status])\n",
    "        year_ls_2[istate,1]  = df_grp_act_Y[act1][etat][status][-2]\n",
    "    if i_application_input:\n",
    "         year_ls_2[istate,0] = year_to_predict\n",
    "    mid_year_ls_2[istate]= np.int((year_ls_2[istate,0] + year_ls_2[istate,1])/2.0)\n",
    "    dYear[istate]        = year_ls_2[istate,0] - year_ls_2[istate,1]\n",
    "    istate+=1\n",
    "print(year_ls_2.transpose())\n",
    "print('middle year',mid_year_ls_2)\n",
    "mean_dYear=int(np.mean(dYear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 2013\n",
      "year 2014\n",
      "year 2013\n",
      "year 2014\n",
      "year 2014\n",
      "year 2014\n",
      "year 2014\n",
      "year 2014\n",
      "year 2013\n",
      "year 2014\n",
      "year 2013\n",
      "year 2014\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------\n",
    "# create input of initial EI \n",
    "#---------------------------------\n",
    "nb_idx=0\n",
    "input_matrix  = np.zeros((len(states_ls_2),nb_inputs))\n",
    "result_matrix = np.zeros((len(states_ls_2),nb_outputs))\n",
    "\n",
    "for in_para in row:\n",
    "    if in_para=='EI': \n",
    "        current_EI_ave = 68.0\n",
    "        nb_etat=0\n",
    "        for etat in states_ls_2:\n",
    "            dEI_temp= df_grp_act_EI[act1][etat][0] - df_grp_act_EI[act1][etat][-1]\n",
    "\n",
    "            temp_array = df_grp_act_EI[act1][etat][-1]\n",
    "            input_matrix[nb_etat,nb_idx] = (temp_array>=current_EI_ave)\n",
    "            \n",
    "            if i_train_input or i_test_input:\n",
    "                if dEI_temp > 10.0:\n",
    "                    result_matrix[nb_etat] = [1,0,0]\n",
    "                elif dEI_temp < -10.0:\n",
    "                    result_matrix[nb_etat] = [0,0,1]\n",
    "                else:\n",
    "                    result_matrix[nb_etat] = [0,1,0]\n",
    "            nb_etat+=1\n",
    "\n",
    "        nb_idx+=1\n",
    "\n",
    "        #print('---------------\\n input matrix:\\n---------------\\n',input_matrix.transpose())\n",
    "        #print('---------------\\n result vector:\\n---------------\\n',result_matrix.transpose())\n",
    "        result_array=list(result_matrix)\n",
    "\n",
    "    if in_para=='dYear':\n",
    "        nb_etat=0\n",
    "        for etat in states_ls_2:\n",
    "            input_matrix[nb_etat,nb_idx] = (dYear[nb_etat]>=mean_dYear)\n",
    "            nb_etat+=1\n",
    "        nb_idx+=1\n",
    "    \n",
    "    if in_para=='GDP':\n",
    "        url='https://v4p4sz5ijk.execute-api.us-east-1.amazonaws.com/anbdata/states/system/economic-stats?api_key=00cfdca0-7039-11e9-9730-617277d0f137&format=json'\n",
    "        response = urllib.request.urlopen(url)\n",
    "        data = json.loads(response.read().decode(\"utf-8\"))\n",
    "        df=pd.DataFrame(data)\n",
    "        df.replace('', 0.0, inplace=True)\n",
    "\n",
    "        df_GDP  = df.groupby(['Year','State',])['GDP'].apply(list)\n",
    "        df_dGDP = df.groupby(['Year','State',])['GDP_growth_pc'].apply(list)\n",
    "        df_corru= df.groupby(['Year','State',])['corruption_wgi'].apply(list)\n",
    "\n",
    "        # for the computation of the global mean at each mid-year\n",
    "        df_GDP_2  = df.groupby(['Year'])['GDP'].apply(list)\n",
    "        df_dGDP_2 = df.groupby(['Year'])['GDP_growth_pc'].apply(list)\n",
    "        df_corru_2= df.groupby(['Year'])['corruption_wgi'].apply(list)\n",
    "         \n",
    "        nb_etat=0\n",
    "        for etat in states_ls_2:\n",
    "            year = int(mid_year_ls_2[nb_etat])\n",
    "            if year>2014:\n",
    "                year = 2014 # no GDP data after 2014\n",
    "            #print(df_GDP_2)\n",
    "            print('year',year)\n",
    "            ave_GDP_mid   = np.mean(df_GDP_2[year])\n",
    "            ave_dGDP_mid  = np.mean(df_dGDP_2[year])\n",
    "            ave_corru_mid = np.mean(df_corru_2[year])\n",
    "            \n",
    "            comp_array=[ave_GDP_mid]#,ave_dGDP_mid,ave_corru_mid]\n",
    "            temp_array=[df_GDP[year,etat]]#,df_dGDP[year,etat],df_corru[year,etat]]\n",
    "            \n",
    "            input_matrix[nb_etat,nb_idx] = (temp_array>=comp_array)\n",
    "            nb_etat+=1\n",
    "           \n",
    "        nb_idx+=1  \n",
    "    if in_para=='ce6': # of first audit year\n",
    "        url='https://v4p4sz5ijk.execute-api.us-east-1.amazonaws.com/anbdata/states/usoap/activity-list?api_key=00cfdca0-7039-11e9-9730-617277d0f137&format=json'\n",
    "        response = urllib.request.urlopen(url)\n",
    "        data = json.loads(response.read().decode(\"utf-8\"))\n",
    "        df=pd.DataFrame(data)\n",
    "        df.replace(np.nan, 0.0, inplace=True)\n",
    "        #print(df.columns)\n",
    "        for i_ce in [in_para,]:\n",
    "            df_CE_temp_0    = df.groupby(['Activity','isFinal',])[i_ce].apply(list)\n",
    "            df_CE_ave_temp  = np.mean(df_CE_temp_0['CMA Audit',1])\n",
    "            df_CE_temp_1    = df.groupby(['Activity','State','isFinal',])[i_ce].apply(list)\n",
    "            nb_etat=0\n",
    "            for etat in states_ls_2:\n",
    "                comp_array3     = df_CE_ave_temp\n",
    "                temp_array3     = df_CE_temp_1['CMA Audit',etat,1][0]\n",
    "                input_matrix[nb_etat][nb_idx] = (temp_array3>=comp_array3)\n",
    "                nb_etat+=1\n",
    "            nb_idx+=1\n",
    "            \n",
    "    if in_para=='ce3': # of first audit year\n",
    "        url='https://v4p4sz5ijk.execute-api.us-east-1.amazonaws.com/anbdata/states/usoap/activity-list?api_key=00cfdca0-7039-11e9-9730-617277d0f137&format=json'\n",
    "        response = urllib.request.urlopen(url)\n",
    "        data = json.loads(response.read().decode(\"utf-8\"))\n",
    "        df=pd.DataFrame(data)\n",
    "        df.replace(np.nan, 0.0, inplace=True)\n",
    "        #print(df.columns)\n",
    "        for i_ce in [in_para,]:\n",
    "            df_CE_temp_0    = df.groupby(['Activity','isFinal',])[i_ce].apply(list)\n",
    "            df_CE_ave_temp  = np.mean(df_CE_temp_0['CMA Audit',1])\n",
    "            df_CE_temp_1    = df.groupby(['Activity','State','isFinal',])[i_ce].apply(list)\n",
    "            nb_etat=0\n",
    "            for etat in states_ls_2:\n",
    "                comp_array3     = df_CE_ave_temp\n",
    "                temp_array3     = df_CE_temp_1['CMA Audit',etat,1][0]\n",
    "                input_matrix[nb_etat][nb_idx] = (temp_array3>=comp_array3)\n",
    "                nb_etat+=1\n",
    "            nb_idx+=1\n",
    "            \n",
    "    if in_para=='ce2': # of first audit year\n",
    "        url='https://v4p4sz5ijk.execute-api.us-east-1.amazonaws.com/anbdata/states/usoap/activity-list?api_key=00cfdca0-7039-11e9-9730-617277d0f137&format=json'\n",
    "        response = urllib.request.urlopen(url)\n",
    "        data = json.loads(response.read().decode(\"utf-8\"))\n",
    "        df=pd.DataFrame(data)\n",
    "        df.replace(np.nan, 0.0, inplace=True)\n",
    "        #print(df.columns)\n",
    "        for i_ce in [in_para,]:\n",
    "            df_CE_temp_0    = df.groupby(['Activity','isFinal',])[i_ce].apply(list)\n",
    "            df_CE_ave_temp  = np.mean(df_CE_temp_0['CMA Audit',1])\n",
    "            df_CE_temp_1    = df.groupby(['Activity','State','isFinal',])[i_ce].apply(list)\n",
    "            nb_etat=0\n",
    "            for etat in states_ls_2:\n",
    "                comp_array3     = df_CE_ave_temp\n",
    "                temp_array3     = df_CE_temp_1['CMA Audit',etat,1][0]\n",
    "                input_matrix[nb_etat][nb_idx] = (temp_array3>=comp_array3)\n",
    "                nb_etat+=1\n",
    "            nb_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EI', 'dYear', 'GDP', 'ce6', 'ce3', 'ce2']\n",
      "\n",
      " Creating application data by: \n",
      " ['PRK', 'TLS', 'COM', 'ZWE', 'TUN', 'TKM', 'OMN', 'SAU', 'BOL', 'COL', 'CIV', 'SEN']\n"
     ]
    }
   ],
   "source": [
    "### write csv file\n",
    "#print(list(row))\n",
    "def flattenList(data):\n",
    "    results = []\n",
    "    for rec in data:\n",
    "        if isinstance(rec, list):\n",
    "            results.extend(rec)\n",
    "            results = flattenList(results)\n",
    "        else:\n",
    "            results.append(rec)\n",
    "    return results\n",
    "rowname =  flattenList(row)\n",
    "print(rowname)\n",
    "\n",
    "if i_train_input:\n",
    "    print('\\n Creating training data by: \\n',states_ls_2)\n",
    "    savedata = pd.DataFrame(input_matrix,index=states_ls_2)\n",
    "    savedata.to_csv(\"EI_training_input_with_header.csv\", header=rowname,index=states_ls_2)\n",
    "    savedata.to_csv(\"EI_training_input.csv\", header=False,index=False)\n",
    "    savedata = pd.DataFrame(result_matrix,index=states_ls_2)\n",
    "    savedata.to_csv(\"EI_training_output.csv\", header=False,index=False)\n",
    "    savedata.to_csv(\"EI_training_output_with_header.csv\", header=False,index=states_ls_2)\n",
    "if i_test_input:\n",
    "    print('\\n Creating validation data by: \\n',states_ls_2)\n",
    "    savedata = pd.DataFrame(input_matrix,index=states_ls_2)\n",
    "    savedata.to_csv(\"EI_validation_input.csv\", header=False,index=False)\n",
    "    savedata = pd.DataFrame(result_matrix,index=states_ls_2)\n",
    "    savedata.to_csv(\"EI_validation_output.csv\", header=False,index=False)\n",
    "\n",
    "if i_application_input:\n",
    "    print('\\n Creating application data by: \\n',states_ls_2)\n",
    "    savedata = pd.DataFrame(input_matrix,index=states_ls_2)\n",
    "    savedata.to_csv(\"EI_application_input.csv\", header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
